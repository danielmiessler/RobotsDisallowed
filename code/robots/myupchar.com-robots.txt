# See http://www.robotstxt.org/robotstxt.html for documentation on how to use the robots.txt file
#
# To ban all spiders from the entire site uncomment the next two lines:
User-agent: *
Disallow: /search
Disallow: /r/
Disallow: /product/
Disallow: /supplier/save_review
Disallow: /supplier/save_review_vote
Disallow: /product/ask_review_mail
Disallow: /product/description
Disallow: /users/
Disallow: /cart/
Disallow: /symptom/*/search*

#Baiduspider
User-agent: Baiduspider
Disallow: /

#Yandex
User-agent: Yandex
Disallow: /

User-agent: deepcrawl
Disallow: /
